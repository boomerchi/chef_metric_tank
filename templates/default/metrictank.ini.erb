# config for metric_tank -- managed by Chef

## misc ##

# instance identifier. must be unique. used in clustering messages, for naming queue consumers and emitted metrics.
instance = <%= @node['metrictank']['instance'] %>

# accounting period to track per-org usage metrics
accounting-period = <%= @node['metrictank']['accounting_period'] %>

## data ##

# see https://github.com/raintank/metrictank/blob/master/docs/data-knobs.md for more details
# duration of raw chunks. e.g. 10min, 30min, 1h, 90min...
chunkspan = <%= @node['metrictank']['chunkspan'] %>
# number of raw chunks to keep in memory. should be at least 1 more than what's needed to satisfy aggregation rules
numchunks = <%= @node['metrictank']['numchunks'] %>
# minimum wait before raw metrics are removed from storage
ttl = <%= @node['metrictank']['ttl'] %>

# max age for a chunk before to be considered stale and to be persisted to Cassandra
chunk-max-stale = <%= @node['metrictank']['chunk_max_stale'] %>
# max age for a metric before to be considered stale and to be purged from memory
metric-max-stale = <%= @node['metrictank']['metric_max_stale'] %>
# Interval to run garbage collection job
gc-interval = <%= @node['metrictank']['gc_interval'] %>

# duration before secondary nodes start serving requests
# shorter warmup means metrictank will need to query cassandra more if it doesn't have requested data yet.
# in clusters, best to assure the primary has saved all the data that a newly warmup instance will need to query, to prevent gaps in charts
warm-up-period = <%= @node['metrictank']['warm_up_period'] %>

# settings for rollups (aggregation for archives)
# comma-separated list of archive specifications.
# archive specification is of the form: aggSpan:chunkSpan:numChunks:TTL[:ready as bool. default true]
# with these aggregation rules: 5min:1h:2:3mon,1h:6h:2:1y:false
# 5 min of data, store in a chunk that lasts 1hour, keep 2 chunks in memory, keep for 3months in cassandra
# 1hr worth of data, in chunks of 6 hours, 2 chunks in mem, keep for 1 year, but this series is not ready yet for querying.
# When running a cluster of metrictank instances, all instances should have the same agg-settings.
# chunk spans must be valid values as described here https://github.com/raintank/metrictank/blob/master/docs/data-knobs.md
agg-settings = <%= @node['metrictank']['agg_settings'] %>

## metric data storage in cassandra ##

# see https://github.com/raintank/metrictank/blob/master/docs/cassandra.md for more details
# comma-separated list of hostnames to connect to
cassandra-addrs = <%= @node['metrictank']['cassandra_addrs'] %>
# keyspace to use for storing the metric data table
cassandra-keyspace = <%= @node['metrictank']['cassandra_keyspace'] %>
# desired write consistency (any|one|two|three|quorum|all|local_quorum|each_quorum|local_one
cassandra-consistency = <%= @node['metrictank']['cassandra_consistency'] %>
# how to select which hosts to query
# roundrobin                : iterate all hosts, spreading queries evenly.
# hostpool-simple           : basic pool that tracks which hosts are up and which are not.
# hostpool-epsilon-greedy   : prefer best hosts, but regularly try other hosts to stay on top of all hosts.
# tokenaware,roundrobin              : prefer host that has the needed data, fallback to roundrobin.
# tokenaware,hostpool-simple         : prefer host that has the needed data, fallback to hostpool-simple.
# tokenaware,hostpool-epsilon-greedy : prefer host that has the needed data, fallback to hostpool-epsilon-greedy.
cassandra-host-selection-policy = <%= @node['metrictank']['cassandra_host_selection_policy'] %>
# cassandra timeout in milliseconds
cassandra-timeout = <%= @node['metrictank']['cassandra_timeout'] %>
# max number of concurrent reads to cassandra
cassandra-read-concurrency = <%= @node['metrictank']['cassandra_read_concurrency'] %>
# max number of concurrent writes to cassandra
cassandra-write-concurrency = <%= @node['metrictank']['cassandra_write_concurrency'] %>
# max number of outstanding reads before blocking. value doesn't matter much
cassandra-read-queue-size = <%= @node['metrictank']['cassandra_read_queue_size'] %>
# write queue size per cassandra worker. should be large engough to hold all at least the total number of series expected, divided by how many workers you have
cassandra-write-queue-size = <%= @node['metrictank']['cassandra_write_queue_size'] %>
# how many times to retry a query before failing it
cassandra-retries = <%= @node['metrictank']['cassandra_retries'] %>
# CQL protocol version. cassandra 3.x needs v3 or 4.
cql-protocol-version = <%= @node['metrictank']['cql_protocol_version'] %>

# enable SSL connection to cassandra
cassandra-ssl = <%= @node['metrictank']['cassandra_ssl'] %>
# cassandra CA certficate path when using SSL
cassandra-ca-path = <%= @node['metrictank']['cassandra_ca_path'] %>
# host (hostname and server cert) verification when using SSL
cassandra-host-verification = <%= @node['metrictank']['cassandra_host_verification'] %>
# enable cassandra user authentication
cassandra-auth = <%= @node['metrictank']['cassandra_auth'] %>
# username for authentication
cassandra-username = <%= @node['metrictank']['cassandra_username'] %>
# password for authentication
cassandra-password = <%= @node['metrictank']['cassandra_password'] %>

## Profiling, instrumentation and logging ##

# see https://golang.org/pkg/runtime/#SetBlockProfileRate
block-profile-rate = <%= @node['metrictank']['block_profile_rate'] %>
# 0 to disable. 1 for max precision (expensive!) see https://golang.org/pkg/runtime/#pkg-variables")
mem-profile-rate = <%= @node['metrictank']['mem_profile_rate'] %>

# enable sending statsd messages for instrumentation
statsd-enabled = <%= @node['metrictank']['statsd_enabled'] %>
# statsd address
statsd-addr = <%= @node['metrictank']['statsd_addr'] %>
# standard or datadog
statsd-type = <%= @node['metrictank']['statsd_type'] %>

# inspect status frequency. set to 0 to disable
proftrigger-freq = <%= @node['metrictank']['proftrigger_freq'] %>
# path to store triggered profiles
proftrigger-path = <%= @node['metrictank']['proftrigger_path'] %>
# minimum time between triggered profiles
proftrigger-min-diff = <%= @node['metrictank']['proftrigger_min_diff'] %>
# if process consumes this many bytes (see bytes_sys in dashboard), trigger a heap profile for developer diagnosis
# set it higher than your typical memory usage, but lower than how much RAM the process can take before its get killed
proftrigger-heap-thresh = <%= @node['metrictank']['proftrigger_heap_thresh'] %>

# only log log-level and higher. 0=TRACE|1=DEBUG|2=INFO|3=WARN|4=ERROR|5=CRITICAL|6=FATAL
log-level = <%= @node['metrictank']['log_level'] %>


## http api ##
[http]
# tcp address for metrictank to bind to for its HTTP interface
listen = <%= @node['metrictank']['http']['listen'] %>
# use HTTPS
ssl = <%= @node['metrictank']['http']['ssl'] %>
# SSL certificate file
cert-file = <%= @node['metrictank']['http']['cert_file'] %>
# SSL key file
key-file = <%= @node['metrictank']['http']['key_file'] %>
# limit on how many points could be requested in one request. 1M allows 500 series at a MaxDataPoints of 2000. (0 disables limit)
max-points-per-req = <%= @node['metrictank']['http']['max_points_per_req'] %>
# limit on what kind of time range can be requested in one request. the default allows 500 series of 2 years. (0 disables limit)
max-days-per-req = <%= @node['metrictank']['http']['max_days_per_req'] %>
# only log incoming requests if their timerange is at least this duration. Use 0 to disable
log-min-dur = <%= @node['metrictank']['http']['log_min_dur'] %>


## metric data inputs ##

### carbon input (optional)
[carbon-in]
enabled = <%= @node['metrictank']['carbon_in']['enabled'] %>
# tcp address
addr = <%= @node['metrictank']['carbon_in']['addr'] %>
# represents the "partition" of your data if you decide to partition your data.
partition = <%= @node['metrictank']['carbon_in']['partition'] %>
# needed to know your raw resolution for your metrics. see http://graphite.readthedocs.io/en/latest/config-carbon.html#storage-schemas-conf
# NOTE: does NOT use aggregation and retention settings from this file.  We use agg-settings and ttl for that.
schemas-file = <%= @node['metrictank']['carbon_in']['schemas_file'] %>

### kafka-mdm input (optional, recommended)
[kafka-mdm-in]
enabled = <%= @node['metrictank']['kafka_mdm_in']['enabled'] %>
# tcp address (may be given multiple times as a comma-separated list)
brokers = <%= @node['metrictank']['kafka_mdm_in']['brokers'] %>
# kafka topic (may be given multiple times as a comma-separated list)
topics = <%= @node['metrictank']['kafka_mdm_in']['topics'] %>
# offset to start consuming from. Can be one of newest, oldest,last or a time duration
# the further back in time you go, the more old data you can load into metrictank, but the longer it takes to catch up to realtime data
offset = <%= @node['metrictank']['kafka_mdm_in']['offset'] %>
# kafka partitions to consume. use '*' or a comma separated list of id's
partitions = <%= @node['metrictank']['kafka_mdm_in']['partitions'] %>
# save interval for offsets
offset-commit-interval = <%= @node['metrictank']['kafka_mdm_in']['offset_commit_interval'] %>
# directory to store partition offsets index. supports relative or absolute paths. empty means working dir.
# it will be created (incl parent dirs) if not existing.
data-dir = <%= @node['metrictank']['kafka_mdm_in']['data_dir'] %>
# The number of metrics to buffer in internal and external channels
channel-buffer-size = <%= @node['metrictank']['kafka_mdm_in']['channel_buffer_size'] %>
# The minimum number of message bytes to fetch in a request
consumer-fetch-min = <%= @node['metrictank']['kafka_mdm_in']['consumer_fetch_min'] %>
# The default number of message bytes to fetch in a request
consumer-fetch-default = <%= @node['metrictank']['kafka_mdm_in']['consumer_fetch_default'] %>
# The maximum amount of time the broker will wait for Consumer.Fetch.Min bytes to become available before it
consumer-max-wait-time = <%= @node['metrictank']['kafka_mdm_in']['consumer_max_wait_time'] %>
#The maximum amount of time the consumer expects a message takes to process
consumer-max-processing-time = <%= @node['metrictank']['kafka_mdm_in']['consumer_max_processing_time'] %>
# How many outstanding requests a connection is allowed to have before sending on it blocks
net-max-open-requests = <%= @node['metrictank']['kafka_mdm_in']['net_max_open_requests'] %>

## basic clustering settings ##
[cluster]
# The primary node writes data to cassandra. There should only be 1 primary node per shardGroup.
primary-node = <%= @node['metrictank']['cluster']['primary_node'] %>
# http/s addresses of other nodes, comma separated. use this if you shard your data and want to query other instances
peers = <%= @node['metrictank']['cluster']['peers'] %>
# Interval to probe peer nodes
probe-interval = <%= @node['metrictank']['cluster']['probe_interval'] %>
# Operating mode of cluster. (single|multi)
mode = <%= @node['metrictank']['cluster']['mode'] %>

## clustering transports for tracking chunk saves between replicated instances ##
### kafka as transport for clustering messages (recommended)
[kafka-cluster]
enabled = <%= @node['metrictank']['kafka_cluster']['enabled'] %>
# tcp address (may be given multiple times as a comma-separated list)
brokers = <%= @node['metrictank']['kafka_cluster']['brokers'] %>
# kafka topic (only one)
topic = <%= @node['metrictank']['kafka_cluster']['topic'] %>
# offset to start consuming from. Can be one of newest, oldest,last or a time duration
offset = <%= @node['metrictank']['kafka_cluster']['offset'] %>
# save interval for offsets
offset-commit-interval = <%= @node['metrictank']['kafka_cluster']['offset_commit_interval'] %>
# directory to store partition offsets index. supports relative or absolute paths. empty means working dir.
# it will be created (incl parent dirs) if not existing.
data-dir = <%= @node['metrictank']['kafka_cluster']['data_dir'] %>

### nsq as transport for clustering messages
[nsq-cluster]
enabled = false

## metric metadata index ##

### in-memory
[memory-idx]
enabled = <%= @node['metrictank']['memory_idx']['enabled'] %>

### in memory, elasticsearch-backed
[elasticsearch-idx]
enabled = <%= @node['metrictank']['elasticsearch_idx']['enabled'] %>
# elasticsearch index name to use
index = <%= @node['metrictank']['elasticsearch_idx']['index'] %>
# Elasticsearch host addresses (multiple hosts can be specified as comma-separated list)
hosts = <%= @node['metrictank']['elasticsearch_idx']['hosts'] %>
# http basic auth
user = <%= @node['metrictank']['elasticsearch_idx']['user'] %>
pass = <%= @node['metrictank']['elasticsearch_idx']['pass'] %>
# how often the retry buffer should be flushed to ES. Valid units are "s", "m", "h"
retry-interval = <%= @node['metrictank']['elasticsearch_idx']['retry_interval'] %>
# max number of concurrent connections to ES
max-conns = <%= @node['metrictank']['elasticsearch_idx']['max_conns'] %>
# max numver of docs to keep in the BulkIndexer buffer
max-buffer-docs = <%= @node['metrictank']['elasticsearch_idx']['max_buffer_docs'] %>
# max delay befoer the BulkIndexer flushes its buffer
buffer-delay-max = <%= @node['metrictank']['elasticsearch_idx']['buffer_delay_max'] %>

### in memory, cassandra-backed
[cassandra-idx]
enabled = <%= @node['metrictank']['cassandra_idx']['enabled'] %>
# Cassandra keyspace to store metricDefinitions in.
keyspace = <%= @node['metrictank']['cassandra_idx']['keyspace'] %>
# comma separated list of cassandra addresses in host:port form
hosts = <%= @node['metrictank']['cassandra_idx']['hosts'] %>
#cql protocol version to use
protocol-version = <%= @node['metrictank']['cassandra_idx']['protocol_version'] %>
# write consistency (any|one|two|three|quorum|all|local_quorum|each_quorum|local_one
consistency = <%= @node['metrictank']['cassandra_idx']['consistency'] %>
# cassandra request timeout
timout = <%= @node['metrictank']['cassandra_idx']['timeout'] %>
# number of concurrent connections to cassandra
num-conns = <%= @node['metrictank']['cassandra_idx']['num_conns'] %>
# Max number of metricDefs allowed to be unwritten to cassandra
write-queue-size = <%= @node['metrictank']['cassandra_idx']['write_queue_size'] %>
#automatically clear series from the index if they have not been seen for this much time.
max-stale =  <%= @node['metrictank']['cassandra_idx']['max_stale'] %>
#Interval at which the index should be checked for stale series.
prune-interval =  <%= @node['metrictank']['cassandra_idx']['prune_interval'] %>
#frequency at which we should update the metricDef lastUpdate field.
update-interval =  <%= @node['metrictank']['cassandra_idx']['update_interval'] %>
#fuzzyness factor for update-interval. should be in the range 0 > fuzzyness <= 1. With an updateInterval of 4hours and fuzzyness of 0.5, metricDefs will be updated every 4-6hours.
update-fuzzyness =  <%= @node['metrictank']['cassandra_idx']['update_fuzzyness'] %>
# enable SSL connection to cassandra
ssl = <%= @node['metrictank']['cassandra_idx']['ssl'] %>
# cassandra CA certficate path when using SSL
ca-path = <%= @node['metrictank']['cassandra_idx']['ca_path'] %>
# host (hostname and server cert) verification when using SSL
host-verification = <%= @node['metrictank']['cassandra_idx']['host_verification'] %>
# enable cassandra user authentication
auth = <%= @node['metrictank']['cassandra_idx']['auth'] %>
# username for authentication
username = <%= @node['metrictank']['cassandra_idx']['username'] %>
# password for authentication
password = <%= @node['metrictank']['cassandra_idx']['password'] %>
